{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b66f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN in Tensorflow ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8caeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist_data .load_data()\n",
    "\n",
    "training_images, test_images = training_images/255.0, test_images/255.0\n",
    "\n",
    "print(training_images.shape)\n",
    "\n",
    "training_images = np.expand_dims(training_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "print(training_images.shape)\n",
    "\n",
    "output_classes = len(set(training_labels))\n",
    "print(\"Number of output classes is: \", output_classes)\n",
    "\n",
    "training_images[0].shape\n",
    "\n",
    "# Assuming you have defined 'training_images' and 'output_classes' appropriately\n",
    "input_layer = Input(shape=training_images[0].shape)\n",
    "conv1 = Conv2D(32, (3,3), strides=2, activation='relu')(input_layer)\n",
    "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3,3), strides=2, activation='relu')(maxpool1)\n",
    "# If you need another convolutional layer\n",
    "# conv3 = Conv2D(128, (3,3), strides=2, activation='relu')(conv2)\n",
    "flat1 = Flatten()(conv2)\n",
    "drop1 = Dropout(0.2)(flat1)\n",
    "dense1 = Dense(512, activation='relu')(drop1)\n",
    "drop2 = Dropout(0.2)(dense1)\n",
    "output_layer = Dense(output_classes, activation='softmax')(drop2)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile and fit the model as necessary\n",
    "model.compile(optimizer = 'adam', loss= 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "model_history = model.fit(training_images, training_labels,\n",
    "epochs=20, validation_data=(test_images, test_labels),\n",
    "verbose=1)\n",
    "\n",
    "output = model.predict(test_images)\n",
    "prediction = np.argmax(output[9])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN in Tensorflow for CIFAR-10 dataset###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ed55f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (50000, 32, 32, 3)\n",
      "Training images shape after expanding dimensions: (50000, 32, 32, 3)\n",
      "Number of output classes is: 10\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5579 - accuracy: 0.4350 - val_loss: 1.3122 - val_accuracy: 0.5186\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2610 - accuracy: 0.5509 - val_loss: 1.1753 - val_accuracy: 0.5769\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1369 - accuracy: 0.5974 - val_loss: 1.0491 - val_accuracy: 0.6222\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0426 - accuracy: 0.6327 - val_loss: 0.9722 - val_accuracy: 0.6598\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9716 - accuracy: 0.6571 - val_loss: 0.9495 - val_accuracy: 0.6701\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Prediction for the 10th test image: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "cifar_dataset = tf.keras.datasets.cifar10\n",
    "(training_images, training_labels), (test_images, test_labels) = cifar_dataset.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "training_images, test_images = training_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(\"Training images shape:\", training_images.shape)\n",
    "\n",
    "# No need to expand dimensions as CIFAR-10 images are already in 3 channels\n",
    "print(\"Training images shape after expanding dimensions:\", training_images.shape)\n",
    "\n",
    "output_classes = len(np.unique(training_labels))\n",
    "print(\"Number of output classes is:\", output_classes)\n",
    "\n",
    "# Model architecture\n",
    "input_layer = Input(shape=training_images.shape[1:])\n",
    "conv1 = Conv2D(32, (3,3), strides=2, activation='relu')(input_layer)\n",
    "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3,3), strides=2, activation='relu')(maxpool1)\n",
    "flat1 = Flatten()(conv2)\n",
    "drop1 = Dropout(0.2)(flat1)\n",
    "dense1 = Dense(512, activation='relu')(drop1)\n",
    "drop2 = Dropout(0.2)(dense1)\n",
    "output_layer = Dense(output_classes, activation='softmax')(drop2)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_history = model.fit(training_images, training_labels, epochs=5, validation_data=(test_images, test_labels), verbose=1)\n",
    "\n",
    "# Predict using the model\n",
    "output = model.predict(test_images)\n",
    "prediction = np.argmax(output[9])\n",
    "print(\"Prediction for the 10th test image:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(test_images[9])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b7796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3994 - accuracy: 0.4966 - val_loss: 1.1535 - val_accuracy: 0.5880\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0619 - accuracy: 0.6267 - val_loss: 0.9982 - val_accuracy: 0.6464\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9103 - accuracy: 0.6806 - val_loss: 0.8853 - val_accuracy: 0.6969\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7958 - accuracy: 0.7229 - val_loss: 0.8217 - val_accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7031 - accuracy: 0.7568 - val_loss: 0.8322 - val_accuracy: 0.7195\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "Prediction for the 10th test image: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "class MyCIFARCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Adjust the accuracy threshold as needed\n",
    "        if logs.get('accuracy') > 0.998:\n",
    "            print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "training_images, test_images = training_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Flatten the training labels for unique class count\n",
    "unique_training_labels = tf.unique(tf.reshape(training_labels, [-1]))[0]\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=training_images.shape[1:]),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    # Output layer with number of classes dynamically determined\n",
    "    Dense(len(unique_training_labels), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = MyCIFARCallback()\n",
    "\n",
    "# Train the model\n",
    "model_history = model.fit(training_images, training_labels, \n",
    "                          epochs=5, \n",
    "                          validation_data=(test_images, test_labels), \n",
    "                          callbacks=[callbacks])\n",
    "\n",
    "# Predict using the model\n",
    "predictions = model.predict(test_images)\n",
    "prediction = tf.argmax(predictions[9]).numpy()\n",
    "\n",
    "print(\"Prediction for the 10th test image:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LeNet(CNN) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical  # Updated import\n",
    "\n",
    "# Load dataset as train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Set numeric type to float32 from uint8\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "\n",
    "# Normalize value to [0, 1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Transform labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)  # Updated function call\n",
    "y_test = to_categorical(y_test, 10)    # Updated function call\n",
    "\n",
    "# Reshape the dataset into 4D array\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "# Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# C1 convolutional layer\n",
    "model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28, 28, 1), padding=\"same\"))\n",
    "\n",
    "# S2 pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# C3 convolutional layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# S4 pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# C5 fully connected convolutional layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# Flatten the CNN output so that we can connect it with fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# FC6 fully connected layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model by calling model.fit() function and pass in the training data, number of epochs, and batch size.\n",
    "# Keras provides a facility to evaluate the loss and accuracy at the end of each epoch\n",
    "hist = model.fit(x=x_train, y=y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model by calling model.evaluate\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss: {:.4f}, accuracy: {:.2f}%\".format(test_score[0], test_score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66323ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LeNet(CNN) adapted to CIFAR-10 dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ae91747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2.0814 - accuracy: 0.2433 - val_loss: 1.9541 - val_accuracy: 0.2955\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.8910 - accuracy: 0.3299 - val_loss: 1.8311 - val_accuracy: 0.3547\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1.8031 - accuracy: 0.3637 - val_loss: 1.7685 - val_accuracy: 0.3777\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 1.7488 - accuracy: 0.3839 - val_loss: 1.7916 - val_accuracy: 0.3731\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 1.7070 - accuracy: 0.4002 - val_loss: 1.6896 - val_accuracy: 0.4028\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.6896 - accuracy: 0.4028\n",
      "Test loss: 1.6896, accuracy: 40.28%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# Adapted C1 convolutional layer for CIFAR-10\n",
    "model.add(layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(32, 32, 3), padding='same'))\n",
    "\n",
    "# S2 pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# Adapted C3 convolutional layer for CIFAR-10\n",
    "model.add(layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# S4 pooling layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# C5 fully connected convolutional layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# Flatten the CNN output so that we can connect it with fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# FC6 fully connected layer\n",
    "model.add(layers.Dense(84, activation='tanh'))  # Increased to 84 neurons as per the original LeNet-5 paper\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "hist = model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss: {:.4f}, accuracy: {:.2f}%\".format(test_score[0], test_score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimized LeNet Code for CIFAR-10 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04ea10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.7987 - accuracy: 0.3637 - val_loss: 1.6673 - val_accuracy: 0.4143\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 1.5901 - accuracy: 0.4424 - val_loss: 1.5066 - val_accuracy: 0.4725\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 1.4427 - accuracy: 0.4932 - val_loss: 1.3989 - val_accuracy: 0.5034\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 1.3416 - accuracy: 0.5242 - val_loss: 1.3493 - val_accuracy: 0.5164\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 1.2755 - accuracy: 0.5464 - val_loss: 1.3161 - val_accuracy: 0.5368\n",
      "Test loss: 1.3161, accuracy: 53.68%\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "Prediction for the 10th test image: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the custom callback for early stopping\n",
    "class MyCIFARCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') > 0.998:\n",
    "            print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Instantiate the LeNet-5 model with updated architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Conv2D(32, (5, 5), activation='tanh', input_shape=(32, 32, 3), padding='same'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(32, (5, 5), activation='tanh', padding='valid'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(84, activation='tanh'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with 'adam' optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks for early stopping\n",
    "callbacks = MyCIFARCallback()\n",
    "\n",
    "# Train the model\n",
    "model_history = model.fit(x_train, y_train, \n",
    "                          epochs=5, \n",
    "                          batch_size=128, \n",
    "                          validation_data=(x_test, y_test), \n",
    "                          callbacks=[callbacks],\n",
    "                          verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss: {:.4f}, accuracy: {:.2f}%\".format(test_score[0], test_score[1]*100))\n",
    "\n",
    "# Predict using the model\n",
    "predictions = model.predict(x_test)\n",
    "prediction = tf.argmax(predictions[9]).numpy()\n",
    "print(\"Prediction for the 10th test image:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fa9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
