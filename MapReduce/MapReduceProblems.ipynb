{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 # UNIQUE WORD COUNT \n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c57731",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "lines = []\n",
    "\n",
    "# split each line in file on each word\n",
    "with open(\"ofMiceAndMenIntro.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \"\")\n",
    "        words = re.split(' ', sentence)\n",
    "        lines.append(words)\n",
    "\n",
    "for line in lines:\n",
    "    for word in line:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "\n",
    "            \n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 # STOPWORDS COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9baad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "\n",
    "\n",
    "with open(\"stopWords.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        stop_word = line.strip().lower()\n",
    "        stop_words.append(stop_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_with_stopwords = {}\n",
    "lines = []\n",
    "\n",
    "def setWord(word):\n",
    "    if word not in word_count_with_stopwords:\n",
    "        word_count_with_stopwords[word] = 1\n",
    "    else:\n",
    "        word_count_with_stopwords[word] += 1\n",
    "\n",
    "with open(\"ofMiceAndMenIntro.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \"\")\n",
    "        words = re.split(' ', sentence)\n",
    "        lines.append(words)\n",
    "\n",
    "# print(stop_words)        \n",
    "for line in lines:\n",
    "    for word in line:\n",
    "        if word not in stop_words: # only set word in dict if not in stop words\n",
    "            setWord(word)\n",
    "            \n",
    "print(word_count_with_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90622b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3 # BIGRAMS COUNT\n",
    "import re\n",
    "word_count_bigrams = {}\n",
    "bigrams = []\n",
    "lines = [] # reinitializing globals\n",
    "\n",
    "def setBigram(word):\n",
    "    if word not in word_count_bigrams:\n",
    "        word_count_bigrams[word] = 1\n",
    "    else:\n",
    "        word_count_bigrams[word] += 1            \n",
    "\n",
    "with open(\"ofMiceAndMenIntro.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \"\")\n",
    "        words = re.split(' ', sentence)\n",
    "        lines.append(words)\n",
    "          \n",
    "for line in lines:\n",
    "    for idx, word in enumerate(line):\n",
    "        if idx == len(line) - 1:\n",
    "            break\n",
    "        else:\n",
    "            bigram = f\"{line[idx]},{line[idx + 1]}\"      \n",
    "            bigrams.append(bigram)\n",
    "\n",
    "for bigram in bigrams:\n",
    "    setBigram(bigram)\n",
    "\n",
    "\n",
    "print(word_count_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "4 # INVERTED INDEX\n",
    "\n",
    "document1 = []\n",
    "document2 = []\n",
    "document3 = []\n",
    "\n",
    "word_source = {}\n",
    "\n",
    "with open(\"ofMiceAndMenIntro.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "        words = re.split(' ', sentence)\n",
    "        document1.append(words)\n",
    "\n",
    "\n",
    "flattened_doc1_list = [word for line in document1 for word in line]\n",
    "\n",
    "\n",
    "with open(\"ofMiceAndMenCh2.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "        words = re.split(' ', sentence)\n",
    "        document2.append(words)\n",
    "        \n",
    "flattened_doc2_list = [word for line in document2 for word in line]\n",
    "\n",
    "        \n",
    "with open(\"ofMiceAndMenCh3.txt\", mode = \"r\") as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "        words = re.split(' ', sentence)\n",
    "        document3.append(words)\n",
    "        \n",
    "flattened_doc3_list = [word for line in document3 for word in line]\n",
    "\n",
    "# combine list and then loop checking if word in combined list is in each of source lists\n",
    "combined_list = flattened_doc1_list + flattened_doc2_list + flattened_doc3_list\n",
    "\n",
    "combined_list_no_dups = list(set(combined_list))\n",
    "\n",
    "# create dictionary from words from combined list \n",
    "for word in combined_list:\n",
    "    if (word in flattened_doc1_list) and (word in flattened_doc2_list) and (word in flattened_doc3_list):\n",
    "        word_source[word] = f'\"Document 1, \"Document 2\", \"Document 3\"' \n",
    "    elif (word in flattened_doc1_list) and (word in flattened_doc2_list):\n",
    "        word_source[word] = f'\"Document 1, \"Document 2\"' \n",
    "    elif (word in flattened_doc1_list) and (word in flattened_doc3_list):\n",
    "        word_source[word] = f'\"Document 1, \"Document 3\"' \n",
    "    elif (word in flattened_doc2_list) and (word in flattened_doc3_list):\n",
    "        word_source[word] = f'\"Document 2\", \"Document 3\"' \n",
    "    elif word in flattened_doc1_list:\n",
    "        word_source[word] = f'\"Document 1\"' \n",
    "    elif word in flattened_doc2_list:\n",
    "        word_source[word] = f'\"Document 2\"' \n",
    "    elif word in flattened_doc3_list:\n",
    "        word_source[word] = f'\"Document 3\"' \n",
    "\n",
    "print(word_source)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
