{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset, Categorical Dataa\n",
    "# buying:   vhigh, high, med, low.\n",
    "# maint:    vhigh, high, med, low.\n",
    "# doors:    2, 3, 4, 5more.\n",
    "# persons:  2, 4, more.\n",
    "# lug_boot: small, med, big.\n",
    "# safety:   low, med, high.\n",
    "# class: unacc, acc, good, vgood\n",
    "\n",
    "car_df = pd.read_csv(\"cars_data/car.data\")\n",
    "print('Dataset Loaded...')\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab966f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to invalid data to numerical data\n",
    "numerical = car_df.drop(columns=['class', 'buying', 'maint', 'lug_boot', 'safety'], axis=1)\n",
    "myMapNum = {'5more': 5, 'more': 5}\n",
    "newNum = numerical.replace(myMapNum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6447679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Cateforical values to numericals\n",
    "categorical = car_df.filter(['buying', 'maint', 'lug_boot', 'safety','class'])\n",
    "myMapCat = {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1, 'small': 1, 'big': 3, 'unacc': 1, 'acc': 2, 'good': 3, 'vgood': 4}\n",
    "newCat = categorical.replace(myMapCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sets to obtain final feature set for classifers\n",
    "myTable = pd.concat([newNum, newCat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef866a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate feature input values from output labels for training model\n",
    "X = myTable.drop(['class'], axis=1)\n",
    "y = myTable.filter(['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40% of data allocated to testing whereas 60% is allocated to training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.40,random_state=0)\n",
    "\n",
    "# # 50% of data allocated to testing whereas 50% is allocated to training\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.50,random_state=0)\n",
    "\n",
    "\n",
    "# # 75% of data allocated to testing whereas 25% is allocated to training\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=0)\n",
    "\n",
    "\n",
    "# # 90% of data allocated to testing whereas 10% is allocated to training\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.10,random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1_LOGISTIC REGRESSION\n",
    "log_clf = LogisticRegression()\n",
    "clf = OneVsRestClassifier(log_clf)\n",
    "classifier = clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# # #make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# #2_Naive Bayes\n",
    "# nb_clf = GaussianNB()\n",
    "# clf = OneVsRestClassifier(nb_clf)\n",
    "# classifier = clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# # #make predictions on the test set\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# len(y_pred)\n",
    "\n",
    "\n",
    "# #3_ID3 Decision tree\n",
    "# tree_clf = DecisionTreeClassifier(criterion='entropy')\n",
    "# clf = OneVsRestClassifier(tree_clf)\n",
    "# classifier = clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# # #make predictions on the test set\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# len(y_pred)\n",
    "\n",
    "\n",
    "#4_RANDOM FOREST CLASSIFIER\n",
    "# rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "# classifier = rf_clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#make predictions on the test set\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# len(y_pred)\n",
    "\n",
    "#evaluating the algorithm on the test set \n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# PERFORMANCE METRICS test set 40% of data, Rows from Confusion Matrix\n",
    "print(\"Testing on 40% of data\")\n",
    "print(\"Weighted Metrics\")\n",
    "print(\"Accuracy:\", np.round(metrics.accuracy_score(y_test, y_pred), 4))\n",
    "print(\"Precision:\", np.round(metrics.precision_score(y_test, y_pred, average='weighted'), 4))\n",
    "print(\"Recall:\", np.round(metrics.recall_score(y_test, y_pred, average='weighted'), 4))\n",
    "print(\"F1 Score:\", np.round(metrics.f1_score(y_test, y_pred, average='weighted'), 4))\n",
    "\n",
    "# # PERFORMANCE METRICS test set 50% of data, Rows from Confusion Matrix\n",
    "# print(\"Testing on 50% of data\")\n",
    "# print(\"Accuracy:\", np.round(metrics.accuracy_score(y_test, y_pred), 4))\n",
    "# print(\"Precision:\", np.round(metrics.precision_score(y_test, y_pred, average='weighted'), 4))\n",
    "# print(\"Recall:\", np.round(metrics.recall_score(y_test, y_pred, average='weighted'), 4))\n",
    "# print(\"F1 Score:\", np.round(metrics.f1_score(y_test, y_pred, average='weighted'), 4))\n",
    "\n",
    "\n",
    "# # PERFORMANCE METRICS test set 25% of data, Rows from Confusion Matrix\n",
    "# print(\"Testing on 25% of data\")\n",
    "# print(\"Accuracy:\", np.round(metrics.accuracy_score(y_test, y_pred), 4))\n",
    "# print(\"Precision:\", np.round(metrics.precision_score(y_test, y_pred, average='weighted'), 4))\n",
    "# print(\"Recall:\", np.round(metrics.recall_score(y_test, y_pred, average='weighted'), 4))\n",
    "# print(\"F1 Score:\", np.round(metrics.f1_score(y_test, y_pred, average='weighted'), 4))\n",
    "\n",
    "\n",
    "# # PERFORMANCE METRICS test set 10% of data, Rows from Confusion Matrix\n",
    "# print(\"Testing on 10% of data\")\n",
    "# print(\"Accuracy:\", np.round(metrics.accuracy_score(y_test, y_pred), 4))\n",
    "# print(\"Precision:\", np.round(metrics.precision_score(y_test, y_pred, average='weighted'), 4))\n",
    "# print(\"Recall:\", np.round(metrics.recall_score(y_test, y_pred, average='weighted'), 4))\n",
    "# print(\"F1 Score:\", np.round(metrics.f1_score(y_test, y_pred, average='weighted'), 4))\n",
    "\n",
    "#Calculate confusion matrix and accuracy score\n",
    "# print('Logistic Regression Metrics')\n",
    "# print('Random Forest Classification Metrics')\n",
    "# print(\"Naive Bayes' Classification Metrics\")\n",
    "# print(\"ID3 Deision Trees\")\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='YlGnBu')\n",
    "# plt.ylabel('Actual label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "# plt.title(all_sample_title, size=15);\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# # per_class_accuracies = {}\n",
    "# classes = [\"unacc\", \"acc\", \"good\", \"vgood\"]\n",
    "\n",
    "# # Calculate the accuracy for each one of our classes\n",
    "# for idx, cls in enumerate(classes):\n",
    "#     # obtain value stored in index cm[0][0] for true negatives\n",
    "#     TN = np.sum(np.delete(np.delete(cm, idx, axis=0), idx, axis=1))\n",
    "    \n",
    "#     # obtain value stored in index cm[1][1] for true positives\n",
    "#     TP = cm[idx, idx]\n",
    "    \n",
    "#     # obtain total predictions TN + TP + FN + FP\n",
    "#     Total = np.sum(cm)\n",
    "    \n",
    "#     # calculate correctly predicted classes over total predictions\n",
    "#     per_class_accuracies[cls] = (TP + TN) / Total\n",
    "\n",
    "# print(\"Per class classification accuracy \", per_class_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
